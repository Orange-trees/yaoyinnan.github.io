<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>scrapy进阶开发 | Yaoyinnan's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">scrapy进阶开发</h1><a id="logo" href="/.">Yaoyinnan's Blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">scrapy进阶开发</h1><div class="post-meta">Jun 13, 2018</div><div class="post-content"><h2 id="Selenium"><a href="#Selenium" class="headerlink" title="Selenium"></a>Selenium</h2><h4 id="爬取动态网页"><a href="#爬取动态网页" class="headerlink" title="爬取动态网页"></a>爬取动态网页</h4><p><a href="http://selenium-python.readthedocs.io/api.html" target="_blank" rel="noopener">官方文档</a></p>
<p>需要先安装selenium：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> pip install selenium</span></span><br></pre></td></tr></table></figure>
<p>需要注意的是selenium是模仿浏览器行为，需要下载driver来搭配。</p>
<table>
<thead>
<tr>
<th><strong>Chrome</strong>:</th>
<th><a href="https://sites.google.com/a/chromium.org/chromedriver/downloads" target="_blank" rel="noopener">https://sites.google.com/a/chromium.org/chromedriver/downloads</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Edge</strong>:</td>
<td><a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/" target="_blank" rel="noopener">https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/</a></td>
</tr>
<tr>
<td><strong>Firefox</strong>:</td>
<td><a href="https://github.com/mozilla/geckodriver/releases" target="_blank" rel="noopener">https://github.com/mozilla/geckodriver/releases</a></td>
</tr>
<tr>
<td><strong>Safari</strong>:</td>
<td><a href="https://webkit.org/blog/6900/webdriver-support-in-safari-10/" target="_blank" rel="noopener">https://webkit.org/blog/6900/webdriver-support-in-safari-10/</a></td>
</tr>
</tbody>
</table>
<p>在tools中新建脚本文件<strong>selenium_spider</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome(executable_path=<span class="string">"E:\download\selenium\chromedriver.exe"</span>)</span><br><span class="line"></span><br><span class="line">browser.get(<span class="string">"https://guang.taobao.com/detail/index.htm?spm=a21bo.2017.2001.3.5af911d9RmltPj&amp;uid=2758542224&amp;sid=8094212425&amp;scm=1007.15939.89001.100200300000000&amp;pvid=40c54281-8e66-4601-84c9-6c4c03d60714&amp;itemid=35109052504"</span>)</span><br><span class="line"></span><br><span class="line">print(browser.page_source)</span><br></pre></td></tr></table></figure>
<p>只需简单几行即可获得js动态加载后的页面内容。</p>
<p>之后只需要再通过Selector来获取具体内容。当然，selenium也有一些解析的方法，可以做一些特定的操作，但是提取内容还是Selector更好。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t_selector = Selector(text=browser.page_source)</span><br><span class="line">print(t_selector.css(<span class="string">".testsetest h1::text"</span>).extract_first())</span><br></pre></td></tr></table></figure>
<h4 id="模拟登陆"><a href="#模拟登陆" class="headerlink" title="模拟登陆"></a>模拟登陆</h4><h5 id="知乎"><a href="#知乎" class="headerlink" title="知乎"></a>知乎</h5><p>使用selenium模拟登陆知乎：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">browser.get(<span class="string">"https://www.zhihu.com/signup?next=%2F"</span>)</span><br><span class="line"></span><br><span class="line">browser.find_element_by_css_selector(<span class="string">".SignContainer-switch span"</span>).click()</span><br><span class="line"></span><br><span class="line">browser.find_element_by_css_selector(<span class="string">".SignFlow-accountInputContainer div input[name='username']"</span>).send_keys(<span class="string">"15953127859"</span>)</span><br><span class="line"></span><br><span class="line">browser.find_element_by_css_selector(<span class="string">".SignFlow-password div div input[name='password']"</span>).send_keys(<span class="string">"yao990415yn"</span>)</span><br><span class="line"></span><br><span class="line">browser.find_element_by_css_selector(<span class="string">".SignFlow-submitButton"</span>).click()</span><br></pre></td></tr></table></figure>
<p>send_keys()：模拟输入</p>
<p>click()：模拟点击</p>
<h5 id="微博"><a href="#微博" class="headerlink" title="微博"></a>微博</h5><p>使用selenium模拟登陆微博：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">browser.maximize_window()</span><br><span class="line">browser.get(<span class="string">"https://www.weibo.com/"</span>)</span><br><span class="line">time.sleep(<span class="number">15</span>)</span><br><span class="line">browser.find_element_by_css_selector(<span class="string">"#loginname"</span>).send_keys(<span class="string">"15953127859"</span>)</span><br><span class="line">browser.find_element_by_css_selector(<span class="string">".info_list.password input[node-type='password']"</span>).send_keys(<span class="string">"yao990415yn"</span>)</span><br><span class="line">browser.find_element_by_css_selector(<span class="string">".info_list.login_btn a[node-type='submitBtn']"</span>).click()</span><br></pre></td></tr></table></figure>
<p>需要注意其中的sleep和maxmize_window()</p>
<p>sleep：由于微博有跳转加载时间，需要停顿一段时间再进行输入操作。</p>
<p>maxmize_window()：因为微博兼容性的原因，若半屏打开会导致登陆部分不在页面中加载，只有全屏才能加载。</p>
<h4 id="模拟下拉页面"><a href="#模拟下拉页面" class="headerlink" title="模拟下拉页面"></a>模拟下拉页面</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">browser.get(<span class="string">"https://www.oschina.net/blog"</span>)</span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    browser.execute_script(<span class="string">"window.scrollTo(0, document.body.scrollHeight); var lenOfPage=document.body.scrollHeight; return lenOfPage"</span>)</span><br><span class="line">    time.sleep(<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>在python中可以直接写JavaScript代码，用browser的<strong>execute_script</strong>方法。</p>
<h4 id="不加载图片"><a href="#不加载图片" class="headerlink" title="不加载图片"></a>不加载图片</h4><p>加载图片耗费大量的运行时间，设置不加载图片可以使我们的爬取更为迅速。</p>
<p>对chromedriver设置对应属性可以通过webdriver.ChromeOptions()来实现。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">chrome_opt = webdriver.ChromeOptions()</span><br><span class="line">prefs = &#123;<span class="string">"profile.managed_default_content_settings.images"</span>: <span class="number">2</span>&#125;</span><br><span class="line">chrome_opt.add_experimental_option(<span class="string">"prefs"</span>, prefs)</span><br><span class="line">browser = webdriver.Chrome(executable_path=<span class="string">"E:\download\selenium\chromedriver.exe"</span>, chrome_options=chrome_opt)</span><br><span class="line">browser.get(<span class="string">"https://www.taobao.com"</span>)</span><br></pre></td></tr></table></figure>
<h4 id="无界面浏览器phantomjs"><a href="#无界面浏览器phantomjs" class="headerlink" title="无界面浏览器phantomjs"></a>无界面浏览器phantomjs</h4><p><a href="http://phantomjs.org/download.html" target="_blank" rel="noopener">下载</a></p>
<p>对于linux系统环境下，需要使用无界面浏览器。对于windows一般依旧采取chrome，因为性能更优。</p>
<p>弊端：多进程情况下phantomjs性能下降会很严重。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">browser = webdriver.PhantomJS(executable_path=<span class="string">"E:\download\phantomjs-2.1.1-windows\\bin\phantomjs.exe"</span>)</span><br><span class="line">browser.get(<span class="string">"https://chaoshi.detail.tmall.com/item.htm?spm=a3204.11641622.4538157102.2.6e237e44lGawqi&amp;pos=2&amp;acm=lb-zebra-355535-4093695.1003.1.3594048&amp;id=41285559396&amp;scm=1003.1.lb-zebra-355535-4093695.FF-hyhsfZA-725677994_B-370100_C-HB_D-41285559396_E-D_G-114.9-FF_41285559396_3594048"</span>)</span><br><span class="line">print(browser.page_source)</span><br><span class="line"><span class="comment"># 关闭</span></span><br><span class="line">browser.quit()</span><br></pre></td></tr></table></figure>
<h2 id="将selenium集成进scrapy"><a href="#将selenium集成进scrapy" class="headerlink" title="将selenium集成进scrapy"></a>将selenium集成进scrapy</h2><p>可以通过middlewares的方式将selenium集成到scrapy中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> HtmlResponse</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JSPageMiddleware</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 通过chrome请求动态网页</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_request</span><span class="params">(self, request, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> spider.name == <span class="string">"jobbole"</span>:</span><br><span class="line">            spider.browser.get(request.url)</span><br><span class="line">            <span class="keyword">import</span> time</span><br><span class="line">            time.sleep(<span class="number">3</span>)</span><br><span class="line">            print(<span class="string">"访问:&#123;0&#125;"</span>.format(request.url))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> HtmlResponse(url=spider.browser.current_url, body=spider.browser.page_source, encoding=<span class="string">"utf-8"</span>, request=request)</span><br></pre></td></tr></table></figure>
<p>其中，开启chromedriver要放置在对应的spider（<strong>jobbole.py</strong>）中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> scrapy.xlib.pydispatch <span class="keyword">import</span> dispatcher</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> signals</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.browser = webdriver.Chrome(executable_path=<span class="string">"E:\download\selenium\chromedriver.exe"</span>)</span><br><span class="line">    super(JobboleSpider, self).__init__()</span><br><span class="line">    dispatcher.connect(self.spider_closed, signals.spider_closed)</span><br></pre></td></tr></table></figure>
<p>并且，要设置当spider结束运行时关闭chromedriver：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">spider_closed</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">    <span class="comment"># 当爬虫退出的时候关闭chrome</span></span><br><span class="line">    print(<span class="string">"spider closed"</span>)</span><br><span class="line">    self.browser.quit()</span><br></pre></td></tr></table></figure>
<p>最终，要记得在<strong>setting</strong>中开启<strong>DOWNLOADER_MIDDLEWARES</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DOWNLOADER_MIDDLEWARES = &#123;</span><br><span class="line">    <span class="string">'ArticleSpider.middlewares.JSPageMiddleware'</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="其他动态网页获取介绍"><a href="#其他动态网页获取介绍" class="headerlink" title="其他动态网页获取介绍"></a>其他动态网页获取介绍</h2><h4 id="pyVirtualDisplay"><a href="#pyVirtualDisplay" class="headerlink" title="pyVirtualDisplay"></a>pyVirtualDisplay</h4><p>运行在<strong>Linux</strong>系统中，可以实现无界面爬取，但效果不如chrome稳定。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyvirtualdisplay <span class="keyword">import</span> Display</span><br><span class="line">display = Display(visible=<span class="number">0</span>, size=(<span class="number">800</span>, <span class="number">600</span>))</span><br><span class="line">display.start()</span><br><span class="line"></span><br><span class="line">browser = webdriver.Chrome()</span><br><span class="line">browser.get()</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<h4 id="scrapy-splash"><a href="#scrapy-splash" class="headerlink" title="scrapy-splash"></a>scrapy-splash</h4><p>它自己运行一个servers，通过http请求的方式以js来执行。</p>
<p>运行在servers，支持分布式。</p>
<h4 id="selenium-grid"><a href="#selenium-grid" class="headerlink" title="selenium grid"></a>selenium grid</h4><p>请求一个服务，通过api的方式发送请求。</p>
<h4 id="splinter"><a href="#splinter" class="headerlink" title="splinter"></a>splinter</h4><p>操控浏览器的解决方案，和selenium很相像，是纯python代码。</p>
<h2 id="scrapy暂停与重启"><a href="#scrapy暂停与重启" class="headerlink" title="scrapy暂停与重启"></a>scrapy暂停与重启</h2><p>可以在spider运行暂停时进行记录，以保证下次开启spider从暂停位置继续。</p>
<p>需要在命令行中进行，因为其终止信号为Ctrl + c，而pycharm中终止并无法发出这一信号。</p>
<blockquote>
<p>Windows：暂停信号：Ctrl + c</p>
<p>Linux：kill -f main.py</p>
</blockquote>
<p>在项目目录下进入虚拟环境后执行下面的语句：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> scrapy crawl jobbole -s JOBDIR=job_info/001</span></span><br></pre></td></tr></table></figure>
<p>需要在项目下新建存放信息的文件夹<strong>job_info</strong></p>
<h2 id="Telnet"><a href="#Telnet" class="headerlink" title="Telnet"></a>Telnet</h2><p><a href="https://docs.scrapy.org/en/latest/topics/telnetconsole.html" target="_blank" rel="noopener">文档</a></p>
<p>可以实现对爬虫的监听：</p>
<p>先在windows功能中开启telent，然后在命令行中输入：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> telent localhost 6023</span></span><br></pre></td></tr></table></figure>
<p>通过<strong>est()</strong>命令来查看当前spider状态。</p>
<p>并且可以打印spider的诸多信息，如setting等。</p>
<h2 id="数据收集"><a href="#数据收集" class="headerlink" title="数据收集"></a>数据收集</h2><p>scrapy自带数据收集器，<a href="https://docs.scrapy.org/en/latest/topics/stats.html" target="_blank" rel="noopener">文档</a></p>
<p>以jobbole为例：</p>
<p>收集伯乐在线所有404的url以及404页面数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">handle_httpstatus_list = [<span class="number">404</span>]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.fail_urls = []</span><br></pre></td></tr></table></figure>
<p>在parse中可以进行判断：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> response.status == <span class="number">404</span>:</span><br><span class="line">    self.fail_urls.append(response.url)</span><br><span class="line">    self.crawler.stats.inc_value(<span class="string">"failed_url"</span>)</span><br></pre></td></tr></table></figure>
<h2 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h2><p><a href="https://docs.scrapy.org/en/latest/topics/signals.html" target="_blank" rel="noopener">文档</a></p>
<p>Scrapy广泛使用信号来通知特定事件发生的时间。您可以捕获Scrapy项目中的一些信号（例如使用<a href="https://docs.scrapy.org/en/latest/topics/extensions.html#topics-extensions" target="_blank" rel="noopener">扩展</a>）来执行其他任务或扩展Scrapy以添加不提供的功能。 </p>
<p>以之前的收集404的url为例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">handle_httpstatus_list = [<span class="number">404</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.fail_urls = []</span><br><span class="line">    dispatcher.connect(self.handle_spider_closed, signals.spider_closed)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handle_spider_closed</span><span class="params">(self, spider,reason)</span>:</span></span><br><span class="line">    self.crawler.ststs.set_value(<span class="string">"failed_urls"</span>, <span class="string">","</span>.join(self.fail_urls))</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>可以在spider关闭（closed）之后输出404的url信息。</p>
</div><div class="tags"><a href="/tags/spider/">spider</a></div><div class="post-nav"><a class="pre" href="/2018/06/17/认识SCI、EI、ISTP、SSCI、INSPEC、SCIE、IEEE、CSCD、CSSCI/">认识SCI、EI、ISTP、SSCI、INSPEC、SCIE、IEEE、CSCD、CSSCI</a><a class="next" href="/2018/06/06/scrapy反爬虫策略/">scrapy反爬虫策略</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/vue/" style="font-size: 15px;">vue</a> <a href="/tags/BT/" style="font-size: 15px;">BT</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/ThinkPHP/" style="font-size: 15px;">ThinkPHP</a> <a href="/tags/spider/" style="font-size: 15px;">spider</a> <a href="/tags/common/" style="font-size: 15px;">common</a> <a href="/tags/sql/" style="font-size: 15px;">sql</a> <a href="/tags/hbase/" style="font-size: 15px;">hbase</a> <a href="/tags/文献推荐/" style="font-size: 15px;">文献推荐</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/10/04/linux登录后出现-bash-4-1-，解决办法以及造成这样的原因/">linux登录后出现-bash-4.1$，解决办法以及造成这样的原因</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/17/py-Hbase/">py-Hbase</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/15/BT/">BT</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/18/Git/">Git</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/16/Vue爬坑/">Vue爬坑</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/12/scrapy分布式爬虫/">scrapy分布式爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/08/py-sql/">py-sql</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/常用sql语句/">常用sql语句</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/17/认识SCI、EI、ISTP、SSCI、INSPEC、SCIE、IEEE、CSCD、CSSCI/">认识SCI、EI、ISTP、SSCI、INSPEC、SCIE、IEEE、CSCD、CSSCI</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/13/scrapy进阶开发/">scrapy进阶开发</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Yaoyinnan's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>