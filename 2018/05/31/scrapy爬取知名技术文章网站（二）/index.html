<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>scrapy爬取知名技术文章网站（二） | Yaoyinnan's Blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">scrapy爬取知名技术文章网站（二）</h1><a id="logo" href="/.">Yaoyinnan's Blog</a><p class="description"></p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">scrapy爬取知名技术文章网站（二）</h1><div class="post-meta">May 31, 2018</div><div class="post-content"><h2 id="爬取完整文章列表"><a href="#爬取完整文章列表" class="headerlink" title="爬取完整文章列表"></a>爬取完整文章列表</h2><h4 id="解析列表页所有文章url"><a href="#解析列表页所有文章url" class="headerlink" title="解析列表页所有文章url"></a>解析列表页所有文章url</h4><p>首先，改变start_urls为列表页url。</p>
<h5 id="第一步："><a href="#第一步：" class="headerlink" title="第一步："></a>第一步：</h5><p>通过分析得到列表页所有文章url的list：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">post_urls = response.css(<span class="string">"#archive .floated-thumb .post-thumb a::attr(href)"</span>).extract()</span><br></pre></td></tr></table></figure>
<p>其中attr(href)可以获取对应html标签的属性的值。</p>
<h5 id="第二步："><a href="#第二步：" class="headerlink" title="第二步："></a>第二步：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> post_url <span class="keyword">in</span> post_urls:</span><br><span class="line">    <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, post_url), callback=self.parse_detail)</span><br></pre></td></tr></table></figure>
<p>通过遍历每一条url，并且将其交给scrapy下载。</p>
<p><strong>yield</strong>：下载</p>
<p><strong>Request方法</strong>：</p>
<p>需要调用scrapy.http</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.http <span class="keyword">import</span> Request</span><br></pre></td></tr></table></figure>
<p>它可以进入url页面，再通过之前编写的解析代码获取其中内容。</p>
<p>其中可以指定url和callback的函数：</p>
<p>callback函数需要指定为该url回调的函数，比如目前解析列表页所有文章url，则需要回调到之前编写的parse_detail解析文章页面函数。</p>
<p><strong>parse.urljoin方法</strong>：因为有的网站的a标签里的href不存放完整的url，需要通过一定的方法将其与域名链接。</p>
<p>需要调用urlib</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br></pre></td></tr></table></figure>
<h4 id="提取下一页"><a href="#提取下一页" class="headerlink" title="提取下一页"></a>提取下一页</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next_urls = response.css(<span class="string">".next.page-numbers::attr(href)"</span>).extract_first(<span class="string">""</span>)</span><br><span class="line"><span class="keyword">if</span> next_urls:</span><br><span class="line">    <span class="keyword">yield</span> Request(url=parse.urljoin(response.url, next_urls), callback=self.parse)</span><br></pre></td></tr></table></figure>
<p>与之前思路相仿，将下一页的url提取出来，回调给本函数即可。</p>
<p>由此过程，便提取了文章列表所有文章的内容，下一步需要将其存入数据库中。</p>
<h2 id="存入数据库"><a href="#存入数据库" class="headerlink" title="存入数据库"></a>存入数据库</h2><h4 id="借助Items格式化存储字段"><a href="#借助Items格式化存储字段" class="headerlink" title="借助Items格式化存储字段"></a>借助Items格式化存储字段</h4><p>首先，再<strong>items.py</strong>中定义自己的Item类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobBoleArticleItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    create_date = scrapy.Field()</span><br><span class="line">    url = scrapy.Field()</span><br><span class="line">    url_object_id = scrapy.Field()</span><br><span class="line">    front_image_url = scrapy.Field()</span><br><span class="line">    front_image_path = scrapy.Field()</span><br><span class="line">    praise_nums = scrapy.Field()</span><br><span class="line">    collection_nums = scrapy.Field()</span><br><span class="line">    comment_nums = scrapy.Field()</span><br><span class="line">    tags = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure>
<p>回到<strong>jobboleList.py</strong>，由于存储在收藏数和评论数是int类型，需要做判断：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 收藏</span></span><br><span class="line">collection_str = response.css(<span class="string">'.bookmark-btn::text'</span>).extract_first()</span><br><span class="line">regex_col = <span class="string">"(.[0-9])"</span></span><br><span class="line">match_re = re.match(regex_col, collection_str)</span><br><span class="line"><span class="keyword">if</span> match_re:</span><br><span class="line">    collection_nums = int(match_re.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    collection_nums = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 评论</span></span><br><span class="line">comment_str = response.css(<span class="string">'a .btn-bluet-bigger::text'</span>).extract_first()</span><br><span class="line">regex_col = <span class="string">"(.[0-9])"</span></span><br><span class="line">match_re = re.match(regex_col, comment_str)</span><br><span class="line"><span class="keyword">if</span> match_re:</span><br><span class="line">    comment_nums = int(match_re.group(<span class="number">0</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    comment_nums = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>再<strong>jobboleList.py</strong>中引入之前定义好的Items类，并对其实例化：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ArticleSpider.items <span class="keyword">import</span> JobBoleArticleItem</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> ...</span></span><br><span class="line"><span class="function">	...</span></span><br><span class="line"><span class="function">	...</span></span><br><span class="line">	article_item = JobBoleArticleItem()</span><br></pre></td></tr></table></figure>
<p>通过实例的items对象，将每篇文章页爬取得字段保存在items对象中进行后续存储操作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将id格式化为md5格式</span></span><br><span class="line">article_item[<span class="string">"url_object_id"</span>] = get_md5(response.url)</span><br><span class="line"></span><br><span class="line">article_item[<span class="string">"title"</span>] = title</span><br><span class="line">article_item[<span class="string">"url"</span>] = response.url</span><br><span class="line">article_item[<span class="string">"create_date"</span>] = create_date</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将提取的日期转化为日期对象</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    create_date = datetime.datetime.strptime(create_date, <span class="string">"%Y/$m/%d"</span>).date()</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    create_date = datetime.datetime.now()</span><br><span class="line"></span><br><span class="line">article_item[<span class="string">"front_image_url"</span>] = [front_image_url]	<span class="comment"># 需要注意，这里传入的是数组！</span></span><br><span class="line"></span><br><span class="line">article_item[<span class="string">"praise_nums"</span>] = praise_nums</span><br><span class="line">article_item[<span class="string">"collection_nums"</span>] = collection_nums</span><br><span class="line">article_item[<span class="string">"comment_nums"</span>] = comment_nums</span><br><span class="line">article_item[<span class="string">"tags"</span>] = tags</span><br><span class="line">article_item[<span class="string">"content"</span>] = content</span><br><span class="line"></span><br><span class="line"><span class="keyword">yield</span> article_item</span><br></pre></td></tr></table></figure>
<p>md5需要引入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ArticleSpider.utils.common <span class="keyword">import</span> get_md5</span><br></pre></td></tr></table></figure>
<p>date对象需要引入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br></pre></td></tr></table></figure>
<h4 id="提取图片"><a href="#提取图片" class="headerlink" title="提取图片"></a>提取图片</h4><p>在<strong>pipelines.py</strong>中定义<strong>ArticleImagePipeline</strong>方法作为管道（需要引入ImagesPipeline）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br></pre></td></tr></table></figure>
<p><strong>ArticleImagePipeline</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArticleImagePipeline</span><span class="params">(ImagesPipeline)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span><span class="params">(self, results, item, info)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> ok, value <span class="keyword">in</span> results:</span><br><span class="line">            image_file_path = value[<span class="string">"path"</span>]</span><br><span class="line">        item[<span class="string">"front_image_path"</span>] = image_file_path</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>注意需要<strong>return item</strong>，以备下一个item传入。</p>
<p>在<strong>setting.py</strong>中开启<strong>ITEM_PIPELINES</strong></p>
<p>先引入os：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure>
<p><strong>ITEM_PIPELINES</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="comment"># 获取image的path</span></span><br><span class="line">    <span class="string">'ArticleSpider.pipelines.ArticleImagePipeline'</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="comment"># 下载图片</span></span><br><span class="line">    <span class="string">'scrapy.pipelines.images.ImagesPipeline'</span>: <span class="number">3</span></span><br><span class="line">&#125;</span><br><span class="line">IMAGES_URLS_FIELD = <span class="string">"front_image_url"</span>   <span class="comment"># 确认所下载字段</span></span><br><span class="line">project_dir = os.path.abspath(os.path.dirname(__file__))   <span class="comment"># 获取当前目录路径</span></span><br><span class="line">IMAGES_STORE = os.path.join(project_dir, <span class="string">"images"</span>)   <span class="comment"># join连接</span></span><br></pre></td></tr></table></figure>
<p>items流经的pipelines（管道），数字代表管道流经顺序（数字越小越先执行）。</p>
<h4 id="存入Json文件"><a href="#存入Json文件" class="headerlink" title="存入Json文件"></a>存入Json文件</h4><p>在pipelines.py中引入json</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br></pre></td></tr></table></figure>
<p>通过定义“管道“将items对象保存的字段存储如json文件。</p>
<h5 id="自定义Json文件的导出"><a href="#自定义Json文件的导出" class="headerlink" title="自定义Json文件的导出"></a>自定义Json文件的导出</h5><p>首先在<strong>pipelines.py</strong>中定义<strong>JsonWithEncodingPipeline</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonWithEncodingPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 自定义json文件的导出</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = codecs.open(<span class="string">'article.json'</span>, <span class="string">'w'</span>, encoding=<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        lines = json.dumps(dict(item), ensure_ascii=<span class="keyword">False</span>) + <span class="string">'\n'</span></span><br><span class="line">        self.file.write(lines)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">spider_closed</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.file.close()</span><br></pre></td></tr></table></figure>
<p>存入文件article.json</p>
<p>自定义方法存入的内容可能会有一定的问题和错误，需要注意细节。</p>
<h5 id="调用scrapy提供的json-export导出json文件"><a href="#调用scrapy提供的json-export导出json文件" class="headerlink" title="调用scrapy提供的json_export导出json文件"></a>调用scrapy提供的json_export导出json文件</h5><p>首先引入<strong>JsonItemExporter</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> scrapy.exporters <span class="keyword">import</span> JsonItemExporter</span><br></pre></td></tr></table></figure>
<p>在<strong>pipelines.py</strong>中定义<strong>JsonExporterPipleline</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JsonExporterPipleline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 调用scrapy提供的json_export导出json文件</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.file = open(<span class="string">'articleexport.json'</span>, <span class="string">'wb'</span>)</span><br><span class="line">        self.exporter = JsonItemExporter(self.file, encoding=<span class="string">"utf-8"</span>, ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line">        self.exporter.start_exporting()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spoder</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        self.exporter.finish_exporting()</span><br><span class="line">        self.file.close()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        self.exporter.export_item(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>最后，在<strong>setting.py</strong>中开启管道<strong>JsonWithEncodingPipeline</strong>或<strong>JsonExporterPipleline</strong>。</p>
<p>Exporter中还提供有存储成其他类型文件的方式，可以Ctrl+自行查看。</p>
<h4 id="存入数据库-1"><a href="#存入数据库-1" class="headerlink" title="存入数据库"></a>存入数据库</h4><p>数据表设计：</p>
<table>
<thead>
<tr>
<th>字段</th>
<th>类型</th>
<th>空</th>
<th>默认</th>
<th>注释</th>
</tr>
</thead>
<tbody>
<tr>
<td>title</td>
<td>varchar(200)</td>
<td>否</td>
<td></td>
<td></td>
</tr>
<tr>
<td>create_date</td>
<td>date</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>url</td>
<td>varchar(300)</td>
<td>否</td>
<td></td>
<td></td>
</tr>
<tr>
<td>url_object_id</td>
<td>varchar(50)</td>
<td>否</td>
<td></td>
<td></td>
</tr>
<tr>
<td>front_image_url</td>
<td>varchar(300)</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>front_image_path</td>
<td>varchar(200)</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>praise_nums</td>
<td>int(11)</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>collection_nums</td>
<td>int(11)</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>comment_nums</td>
<td>int(11)</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>tags</td>
<td>varchar(200)</td>
<td>是</td>
<td><em>NULL</em></td>
<td></td>
</tr>
<tr>
<td>content</td>
<td>longtext</td>
<td>是</td>
<td><em>NULL</em></td>
</tr>
</tbody>
</table>
<p>方法设计：</p>
<p>首先，引入MySQL：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> MySQLdb</span><br></pre></td></tr></table></figure>
<h5 id="同步机制"><a href="#同步机制" class="headerlink" title="同步机制"></a>同步机制</h5><p>在<strong>pipelines.py</strong>中定义<strong>MysqlPipeline</strong>，自定义的方法是同步机制，同步数据入库，速度慢，易堵塞。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 采用同步的机制,将数据存入数据库,方法一,同步入库,效率低,插入数据库速度跟不上爬取速度</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.conn = MySQLdb.connect(<span class="string">'127.0.0.1'</span>, <span class="string">'article_spider'</span>, <span class="string">'7dKwHJYkXG'</span>, <span class="string">'article_spider'</span>, charset=<span class="string">"utf8"</span>,</span><br><span class="line">                                    use_unicode=<span class="keyword">True</span>)</span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        insert_sql = <span class="string">"insert into jobbole_article(title,create_date,url,url_object_id,front_image_url,front_image_path,praise_nums,collection_nums,comment_nums,tags,content)VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)"</span></span><br><span class="line">        self.cursor.execute(insert_sql, (</span><br><span class="line">            item[<span class="string">'title'</span>], item[<span class="string">'create_date'</span>], item[<span class="string">'url'</span>], item[<span class="string">'url_object_id'</span>], item[<span class="string">'front_image_url'</span>][<span class="number">0</span>],</span><br><span class="line">            item[<span class="string">'front_image_path'</span>],</span><br><span class="line">            item[<span class="string">'praise_nums'</span>], item[<span class="string">'collection_nums'</span>], item[<span class="string">'comment_nums'</span>], item[<span class="string">'tags'</span>], item[<span class="string">'content'</span>]))</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<h5 id="异步机制"><a href="#异步机制" class="headerlink" title="异步机制"></a>异步机制</h5><p>需要先引入cursors</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> MySQLdb.cursors</span><br></pre></td></tr></table></figure>
<p>在<strong>pipelines.py</strong>中定义<strong>MysqlTwistedPipeline</strong>，使用异步方式可以更加迅速地进行对数据库的插入。</p>
<p>先在<strong>setting.py</strong>中配置好数据库：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DataBase config</span></span><br><span class="line"><span class="comment"># 局域网</span></span><br><span class="line"><span class="comment"># MYSQL_HOST = "xxx.xxx.xxx.xxx"</span></span><br><span class="line"><span class="comment"># 本地</span></span><br><span class="line">MYSQL_HOST = <span class="string">"127.0.0.1"</span></span><br><span class="line">MYSQL_DBNAME = <span class="string">"article_spider"</span></span><br><span class="line">MYSQL_USER = <span class="string">"article_spider"</span></span><br><span class="line">MYSQL_PASSWORD = <span class="string">"xxxxxxxxxx"</span></span><br></pre></td></tr></table></figure>
<p><strong>MysqlTwistedPipeline</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MysqlTwistedPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="comment"># 采用异步的机制,将数据存入数据库,方法二，Twiste异步入库,先在settings中配置好数据库配置</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dbpool)</span>:</span></span><br><span class="line">        self.dbpool = dbpool</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings)</span>:</span></span><br><span class="line">        dbparms = dict(</span><br><span class="line">            host=settings[<span class="string">"MYSQL_HOST"</span>],</span><br><span class="line">            db=settings[<span class="string">"MYSQL_DBNAME"</span>],</span><br><span class="line">            user=settings[<span class="string">"MYSQL_USER"</span>],</span><br><span class="line">            password=settings[<span class="string">"MYSQL_PASSWORD"</span>],</span><br><span class="line">            charset=<span class="string">"utf8"</span>,</span><br><span class="line">            cursorclass=MySQLdb.cursors.DictCursor,</span><br><span class="line">            use_unicode=<span class="keyword">True</span>,</span><br><span class="line">        )</span><br><span class="line">        dbpool = adbapi.ConnectionPool(<span class="string">"MySQLdb"</span>, **dbparms)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> cls(dbpool)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment"># 使用twisted将mysql插入变成异步执行</span></span><br><span class="line">        query = self.dbpool.runInteraction(self.do_insert, item)</span><br><span class="line">        query.addErrback(self.handle_error)  <span class="comment"># 处理异常</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle_error</span><span class="params">(self, failure)</span>:</span></span><br><span class="line">        <span class="comment"># 处理异步插入的异常</span></span><br><span class="line">        print(failure)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">do_insert</span><span class="params">(self, cursor, item)</span>:</span></span><br><span class="line">        <span class="comment"># 执行具体的插入</span></span><br><span class="line">        insert_sql = <span class="string">"insert into jobbole_article(title,create_date,url,url_object_id,front_image_url,front_image_path,praise_nums,collection_nums,comment_nums,tags,content)VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)"</span></span><br><span class="line">        cursor.execute(insert_sql, (</span><br><span class="line">            item[<span class="string">'title'</span>], item[<span class="string">'create_date'</span>], item[<span class="string">'url'</span>], item[<span class="string">'url_object_id'</span>], item[<span class="string">'front_image_url'</span>][<span class="number">0</span>],</span><br><span class="line">            item[<span class="string">'front_image_path'</span>],</span><br><span class="line">            item[<span class="string">'praise_nums'</span>], item[<span class="string">'collection_nums'</span>], item[<span class="string">'comment_nums'</span>], item[<span class="string">'tags'</span>], item[<span class="string">'content'</span>]))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure>
<p>其中，使用python自带的dict可以轻松获取setting中配置好的数据库信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@classmethod</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_settings</span><span class="params">(cls, settings)</span>:</span></span><br><span class="line">    dbparms = dict(</span><br><span class="line">        host=settings[<span class="string">"MYSQL_HOST"</span>],</span><br><span class="line">        db=settings[<span class="string">"MYSQL_DBNAME"</span>],</span><br><span class="line">        user=settings[<span class="string">"MYSQL_USER"</span>],</span><br><span class="line">        password=settings[<span class="string">"MYSQL_PASSWORD"</span>],</span><br><span class="line">        charset=<span class="string">"utf8"</span>,</span><br><span class="line">        cursorclass=MySQLdb.cursors.DictCursor,</span><br><span class="line">        use_unicode=<span class="keyword">True</span>,</span><br><span class="line">    )</span><br><span class="line">    dbpool = adbapi.ConnectionPool(<span class="string">"MySQLdb"</span>, **dbparms)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> cls(dbpool)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意**dbparms的传入方式</p>
</blockquote>
<p>对于插入数据库的方法，只需要更改<strong>do_insert</strong>即可。</p>
</div><div class="tags"><a href="/tags/python/">python</a></div><div class="post-nav"><a class="next" href="/2018/05/22/MOOC-ThinkPHP模型篇-2数据库操作/">MOOC-ThinkPHP模型篇-2数据库操作</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/ThinkPHP/" style="font-size: 15px;">ThinkPHP</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/common/" style="font-size: 15px;">common</a> <a href="/tags/图像处理/" style="font-size: 15px;">图像处理</a> <a href="/tags/文献推荐/" style="font-size: 15px;">文献推荐</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/05/31/scrapy爬取知名技术文章网站（二）/">scrapy爬取知名技术文章网站（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/22/MOOC-ThinkPHP模型篇-2数据库操作/">MOOC-ThinkPHP模型篇-2数据库操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/MOOC-ThinkPHP基础篇-5-8模板的布局-包含和继承/">MOOC-ThinkPHP基础篇-5-8模板的布局 包含和继承</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/MOOC-ThinkPHP基础篇-5-6比较标签 5-7条件判断标签/">MOOC-ThinkPHP基础篇-5-6比较标签 5-7条件判断标签</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/MOOC-ThinkPHP基础篇-5-5模板循环标签/">MOOC-ThinkPHP基础篇-5-5模板循环标签</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/MOOC-ThinkPHP基础篇-5-4变量输出-调节器/">MOOC-ThinkPHP基础篇-5-4变量输出 调节器</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/20/MOOC-ThinkPHP基础篇-5-3系统变量原生标签/">MOOC-ThinkPHP基础篇-5-3系统变量原生标签</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/12/图像处理名词/">图像处理名词</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/07/scrapy爬取知名技术文章网站（一）/">scrapy爬取知名技术文章网站（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/03/爬虫技术基础知识/">爬虫技术基础知识</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Yaoyinnan's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.2.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>